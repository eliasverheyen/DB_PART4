{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werkje gegevensbanken 2018 - DEEL 04\n",
    "\n",
    "## Inleiding\n",
    "\n",
    "Het vierde en laatste deel van het werkje bestaat uit twee componenten: \n",
    "1. Optimalisatie\n",
    "2. Visualisatie\n",
    "\n",
    "Bij dit deel van het werkje laten we jullie veel vrijheid om tot een oplossing te komen. Er bestaat niet zoiets als de unieke correcte oplossing, het is dus de bedoeling dat jullie zelf een strategie uitdokteren en deze achteraf kunnen verdedigen. Leg in deze notebook kort uit welke keuzes je maakt en waarom, dit zal helpen bij de verdediging. Beschouw dit als een soort mini-verslag tussen de code door.\n",
    "\n",
    "### Indienen + Evaluatiemoment\n",
    "\n",
    "** EVALULATIEMOMENT**: DE OEFENZITTING IN DE WEEK VAN 14/05/2017-18/05/2017\n",
    "\n",
    "Het evaluatiemoment van het **volledige** werkje vindt plaats tijdens **de oefenzitting in de week van 14/05/2017-18/05/2017**. Prof. Berendt en dr. Bogaerts komen langs om enkele vragen te stellen over jullie oplossingen. Dit evaluatiemoment omvat ook een demonstratie van jullie resultaat, bijvoorbeeld: aantonen dat jullie optimalisatie van deel 4 van het werkje effectief een verbetering is t.o.v. het originele geval. Teneinde die demonstratie vlot te doen verlopen vragen we jullie om **per groep (minstens) 1 laptop mee te nemen waarop jullie oplossingen (i.e. de ingevulde notebooks) goed functioneren**. Deze laptop beschikt dus ook over XAMPP (inclusief de gegevensbank van dit werkje, uiteraard), gezien de queries in de notebooks ook moeten werken.\n",
    "\n",
    "**INDIENDEADLINE**: ZONDAG 13 MEI om 23.59\n",
    "\n",
    "** HOE INDIENEN**:\n",
    "    1. Upload je ingevulde notebook als werkje_04_groep_XX.ipynb EN werkje_04_groep_XX.html \n",
    "    2. Vervang XX door je groepsnummer.\n",
    "    3. Uploaden doe je op Toledo in je groepsfolder.\n",
    "    \n",
    "Zorg ervoor dat de .html file zeker ook de output van de visualisatie bevat, zodat wij deze gemakkelijk kunnen bekijken en niet moeten reproduceren door jullie .ipynb te runnen! Op die manier kunnen we zeker zijn dat we evalueren wat jullie geproduceerd hebben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuttige packages en functies inladen\n",
    "\n",
    "Enkele nuttige packages en functies inladen die verderop van pas zullen komen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benodigde packages\n",
    "import json            # Package om .json files in te laden (bvb kolomnamen zijn zo opgeslagen)\n",
    "import getpass         # Package om een paswoordveldje te genereren.\n",
    "import mysql.connector # MySQL package\n",
    "import numpy as np\n",
    "import pandas as pd    # Populaire package voor data-verwerking\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version_info       # Check python versie, wij veronderstellen 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interageren met een gegevensbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbind_met_GB(username, hostname, gegevensbanknaam):\n",
    "    \"\"\"\n",
    "    Maak verbinding met een externe gegevensbank\n",
    "    \n",
    "    :param  username:          username van de gebruiker, string\n",
    "    :param  hostname:          naam van de host, string.\n",
    "                               Dit is in het geval van een lokale server gewoon 'localhost'\n",
    "    :param  gegevensbanknaam:  naam van de gegevensbank, string.\n",
    "    :return connection:        connection object, dit is wat teruggeven wordt \n",
    "                               door connect() methods van packages die voldoen aan de DB-API\n",
    "    \"\"\"\n",
    "    \n",
    "    password = getpass.getpass() # Genereer vakje voor wachtwoord in te geven\n",
    "    \n",
    "    connection = mysql.connector.connect(host=hostname,\n",
    "                                         user=username,\n",
    "                                         passwd=password,\n",
    "                                         db=gegevensbanknaam)\n",
    "    return connection\n",
    "\n",
    "\n",
    "def check_perfect_match(df1, df2):\n",
    "    \"\"\"\n",
    "    Functie om te checken of 2 DataFrames gelijk zijn.\n",
    "    \"\"\"\n",
    "    check = df1.equals(df2)\n",
    "    return check\n",
    "\n",
    "\n",
    "def run_query(connection, query):\n",
    "    \"\"\"\n",
    "    Voer een query uit op een reeds gemaakte connectie, geeft het resultaat van de query terug\n",
    "    \"\"\"\n",
    "    \n",
    "    # Making a cursor and executing the query\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    # Collecting the result and casting it in a pd.DataFrame\n",
    "    res = cursor.fetchall()\n",
    "    \n",
    "    return res\n",
    "\n",
    "#ZELF GEDEFINIEERDE QUERY\n",
    "def run_multistatement_query(connection, query):\n",
    "    \"\"\"\n",
    "    Voer een query met meerdere statements uit op een reeds gemaakte connectie, geeft het resultaat van de query terug\n",
    "    \"\"\"\n",
    "    \n",
    "    # Making a cursor and executing the query\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query, multi = True)\n",
    "    \n",
    "    # Collecting the result and casting it in a pd.DataFrame\n",
    "    res = cursor.fetchall()\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def res_to_df(query_result, column_names):\n",
    "    \"\"\"\n",
    "    Giet het resultaat van een uitgevoerde query in een 'pandas dataframe'\n",
    "    met vooraf gespecifieerde kolomnamen.\n",
    "    \n",
    "    Let op: Het resultaat van de query moet dus exact evenveel kolommen bevatten\n",
    "    als kolomnamen die je meegeeft. Als dit niet het geval is, is dit een indicatie\n",
    "    dat je oplossing fout is. (Gezien wij de kolomnamen van de oplossing al cadeau doen)\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(query_result, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimalisatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave\n",
    "\n",
    "Het doel van het eerste deel van deze taak is het optimaliseren van onderstaande query.\n",
    "\n",
    "Een goede oplossing van deze eerste opgave voldoet aan volgende criteria:\n",
    "* Verzin een optimalisatie van deze query\n",
    "* De runtime van de optimalisatie is significant minder dan die van de originele oplossing (een paar procent is te weinig)\n",
    "* Je bent in staat om uit te leggen WAT je doet en WAAROM je dat gedaan hebt en WAAROM het werkt..\n",
    "    * Het EXPLAIN statement in MySQL is een goede gids om je hierbij te helpen. \n",
    "    * Je schrijft in deze notebook al kort de redeneringen op die achter jullie optimalisatie zitten (dit zal nuttig zijn bij de mondelinge verdediging).\n",
    "\n",
    "Hieronder vinden jullie de query die te optimaliseren is. Wijzig deze dus niet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beschrijving**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het resultaat van deze functie is een Pandas DataFrame dat voor een gegeven *jaar_1* een aantal statistieken van alle staten bevat waarbij de gemiddelde lengte van alle spelers geboren in die staat en opgenomen in de hall of fame na *jaar_2* groter is dan *lengte*.\n",
    "\n",
    "Voor die staten moet de tabel de volgende statistieken bevatten: het gemiddelde gewicht, de gemiddelde lengte, het gemiddeld aantal batting homeruns, en het gemiddeld aantal pitching saves van alle spelers (geboren in die staat) die in de hall of fame zijn opgenomen na *jaar_2*.\n",
    "\n",
    "Sorteer oplopend alfabetisch op staat.\n",
    "\n",
    "Nb. Lengte is uitgedrukt in inches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['state', 'avg_weight', 'avg_height', 'avg_homeruns', 'avg_saves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit is de originele query die geoptimaliseerd dient te worden. Niet wijzigen!\n",
    "def query_to_optimize(connection, column_names, jaar_1=2000, jaar_2=1990, lengte=75):\n",
    "    # Actual query\n",
    "    query=\"\"\"\n",
    "    SELECT m.birthState, AVG(m.weight), AVG(m.height), AVG(bat.HR), AVG(pit.SV)\n",
    "    FROM Master AS m,\n",
    "        Pitching AS pit,\n",
    "        Batting AS bat,\n",
    "        HallOfFame AS hof\n",
    "    WHERE pit.yearID = {}\n",
    "        AND bat.yearID = {}\n",
    "        AND pit.playerID = m.playerID\n",
    "        AND bat.playerID = m.playerID\n",
    "        AND m.playerID = hof.playerID\n",
    "        AND hof.yearID > {}\n",
    "    GROUP BY m.birthState\n",
    "    HAVING AVG(m.height) > {}\n",
    "    ORDER BY m.birthState ASC;\n",
    "    \"\"\".format(jaar_1, jaar_1, jaar_2, lengte)\n",
    "    \n",
    "    # Stap 2 & 3\n",
    "    res = run_query(connection, query)         # Query uitvoeren\n",
    "    df = res_to_df(res, column_names)          # Query in DataFrame brengen\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst maken we verbinding met de gegevensbank, zoals jullie al deden in het vorige deel van het werkje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "username = 'root'      # Vervang dit als je via een andere user queries stuurt\n",
    "hostname = 'localhost' # Als je een databank lokaal draait, is dit localhost.\n",
    "db = 'lahman2016'      # Naam van de gegevensbank op je XAMPP Mysql server\n",
    "\n",
    "# We verbinden met de gegevensbank\n",
    "c1 = verbind_met_GB(username, hostname, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In onderstaande cel bekomen we de runtime van de originele query door deze vijf keer te runnen, om tot een betere schatting te komen. Deze conventie van runtimes meten dient behouden te worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De originele query duurt:  1.39  seconden\n"
     ]
    }
   ],
   "source": [
    "timings=[]\n",
    "\n",
    "# We voeren deze query 5 keer uit om een betere schatting te krijgen van de effectieve runtime.\n",
    "for i in range(5):\n",
    "    t1 = time.time() # Start time\n",
    "    df_orig = query_to_optimize(c1, column_names, jaar_1=2000, jaar_2=1990, lengte=75)\n",
    "    t2 = time.time() # Stop time\n",
    "    timings.append(t2-t1) \n",
    "    \n",
    "orig_runtime=np.mean(timings) # De uiteindelijke runtime is een gemiddelde van 5 runs.\n",
    "\n",
    "print('De originele query duurt: ', \"{0:.2f}\".format(orig_runtime),' seconden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimalisatie\n",
    "\n",
    "In deze sectie is het de bedoeling dat je je optimalisatie realiseert. Wat hier al ingevuld staat qua code is enkel om je op weg te helpen.\n",
    "\n",
    "Je mag zoveel codecellen toevoegen als je nodig acht om je verhaal te vertellen. Leg uit wat je doet, en waarom je dat doet. Denk hierbij zeker aan het EXPLAIN statement zoals gezien in de les. Gebruik EXPLAIN om te identificeren hoe MySQL de query omzet en kijk zo welke effecten je verbeteringen hebben. Leg de resultaten van EXPLAIN kort uit.\n",
    "\n",
    "Beschouw de uitleg rond je oplossing als een soort mini-verslag dat je code en query uitlegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Explain origineel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain uitvoeren op de originele query levert, kort samengevat, volgende resultaten:\n",
    "- alle tabellen uit de query worden gebruikt, dat zijn er 4\n",
    "- nergens zijn keys mogelijk te gebruiken / zijn ze gebruikt\n",
    "- het verwachte aantal te lezen rows is het totale aantal rows\n",
    "- er worden temporary tables aangemaakt\n",
    "- er wordt gesorteerd\n",
    "- overal worden where conditions gebruikt\n",
    "- 3 joins, BNL joins met buffers, eventueel incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken voor ieder gebruikt attribuut een index aan in de hoop de query te versnellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: output\n"
     ]
    }
   ],
   "source": [
    "%%capture #suppress output\n",
    "'''\n",
    "    CREATE INDEX mpid ON Master(playerID);\n",
    "    CREATE INDEX ppid ON Pitching(PlayerID);\n",
    "    CREATE INDEX bpid ON Batting(PlayerID);\n",
    "    CREATE INDEX hpid ON HallOfFame(PlayerID);\n",
    "    CREATE INDEX pyid ON Pitching(YearID);\n",
    "    CREATE INDEX byid ON Batting(YearID);\n",
    "    CREATE INDEX hyid ON HallOfFame(YearID);\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We merken echter op dat het creëren van de indexen door de grootte van de database zeer traag verloopt. Door het gebruik van het explain-statement zien we dat ook niet alle gecreëerde indexen gebruikt worden. Enkel pyid, hpid, mpid en bpid worden gebruikt. Bijgvolg verwijderen de creatie van alle andere indexen uit het bovenstaande commando. We maken een tweede database 'lahman_indexed' aan en voeren onderstaande SQL-code uit op deze database. Dit gebeurt vanuit phpMyAdmin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: output\n"
     ]
    }
   ],
   "source": [
    "%%capture #suppress output\n",
    "\"\"\"\n",
    " CREATE INDEX bpid ON Batting(PlayerID);\n",
    " CREATE INDEX hpid ON HallOfFame(PlayerID);\n",
    " CREATE INDEX pyid ON Pitching(YearID);\n",
    " CREATE INDEX mpid ON Master(PlayerID);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De query die we vervolgens uitvoeren, is precies dezelfde als die we reeds gekregen hebben. We vinden geen manier om de query zelf te herschrijven waardoor deze efficiënter zou worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak hier je eerste optimalisatie\n",
    "def optim_1(connection, column_names, jaar_1=2000, jaar_2=1990, lengte=75):\n",
    "    query=\"\"\"\n",
    "    SELECT m.birthState, AVG(m.weight), AVG(m.height), AVG(bat.HR), AVG(pit.SV)\n",
    "    FROM Master AS m,\n",
    "        Pitching AS pit,\n",
    "        Batting AS bat,\n",
    "        HallOfFame AS hof\n",
    "    WHERE pit.yearID = {}\n",
    "        AND bat.yearID = {}\n",
    "        AND pit.playerID = m.playerID\n",
    "        AND bat.playerID = m.playerID\n",
    "        AND m.playerID = hof.playerID\n",
    "        AND hof.yearID > {}\n",
    "    GROUP BY m.birthState\n",
    "    HAVING AVG(m.height) > {}\n",
    "    ORDER BY m.birthState ASC;\n",
    "    \"\"\".format(jaar_1, jaar_1, jaar_2, lengte)\n",
    "    \n",
    "    # Stap 2 & 3\n",
    "    res = run_query(connection, query)         # Query uitvoeren\n",
    "    df = res_to_df(res, column_names)          # Query in DataFrame brengen\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Explain optimalisatie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain uitvoeren op de query in de indexed database levert, kort samengevat, volgende resultaten:\n",
    "- 3 van de 4 tabellen worden via een key betreden\n",
    "- het verwachte aantal te lezen rows is veel lager\n",
    "- slechts 1 join, BNL join met buffer\n",
    "\n",
    "Bleef hetzelde:\n",
    "- alle tabellen uit de query worden gebruikt, dat zijn er 4\n",
    "- worden temporary tables aangemaakt\n",
    "- wordt gesorteerd\n",
    "- overal worden where conditions gebruikt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten slotte moeten we nog een nieuwe connectie maken om te verbinden met de lahman_indexed database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "username = 'root'      # Vervang dit als je via een andere user queries stuurt\n",
    "hostname = 'localhost' # Als je een databank lokaal draait, is dit localhost.\n",
    "db = 'lahman2016_indexed'      # Naam van de gegevensbank op je XAMPP Mysql server\n",
    "\n",
    "# We verbinden met de gegevensbank\n",
    "c2 = verbind_met_GB(username, hostname, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controle\n",
    "\n",
    "De onderstaande codecel vergelijkt de runtime van de optimalisatie met die van de originele query, door een gemiddelde te nemen over 5 runs. Ook wordt er nagegaan dat de resultaten zeker volledig gelijk zijn. Wijzig deze controlewijze niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De optimalisatie duurt:  0.29  seconden\n",
      "De originele versie duurde:  1.39  seconden\n",
      "De netto tijdwinst is dus:  1.11  seconden, oftewel 79.43 %\n",
      "Is het resultaat equivalent?  True\n"
     ]
    }
   ],
   "source": [
    "# Test hier je eerste optimalisatie\n",
    "\n",
    "timings_optim_1 = []\n",
    "for i in range(5):\n",
    "    t1 = time.time() # Start time\n",
    "    df_optim_1 = optim_1(c2, column_names, jaar_1=2000, jaar_2=1990, lengte=75)\n",
    "    t2 = time.time() # Stop time\n",
    "    timings_optim_1.append(t2-t1) \n",
    "    \n",
    "optim_1_runtime = np.mean(timings_optim_1) # Runtime optimalisatie 1\n",
    "\n",
    "# Vergelijken met originele query\n",
    "diff = orig_runtime-optim_1_runtime # Winst t.o.v. origineel\n",
    "rel_diff = diff/orig_runtime # Relatieve winst\n",
    "check = check_perfect_match(df_orig,df_optim_1) # Nagaan of de resultaten exact gelijk zijn.\n",
    "\n",
    "# Belangrijkste resultaten printen.\n",
    "print('De optimalisatie duurt: ', \"{0:.2f}\".format(optim_1_runtime),' seconden')\n",
    "print('De originele versie duurde: ', \"{0:.2f}\".format(orig_runtime),' seconden')\n",
    "print('De netto tijdwinst is dus: ',\"{0:.2f}\".format(diff),' seconden, oftewel', \"{0:.2f}\".format(100*rel_diff), '%' )\n",
    "print('Is het resultaat equivalent? ', check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisatie\n",
    "\n",
    "### Opgave\n",
    "\n",
    "In het laatste onderdeel van het werkje laten we jullie volledig vrij. Jullie hebben ondertussen geleerd om data uit een gegevensbank op te halen, de volgende stap is om deze data effectief voor iets nuttigs te gebruiken.\n",
    "\n",
    "Een snelle manier om gegevens overzichtelijk weer te geven is visualisatie. Een goede visualisatie kan zeker in een eerste fase van data-analyse echt al inzichten verschaffen. Wij vragen dus aan jullie een of meerdere visualisaties te realiseren, met data uit de gegevensbank die jullie voor dit werkje gebruikt hebben.\n",
    "\n",
    "Een goede oplossing van deze opgave voldoet aan volgende criteria:\n",
    "* Schrijf een query die informatie uit de gegevensbank ophaalt, en in een DataFrame stopt.\n",
    "* Maak een interessante visualisatie van (een deel van) de data in die DataFrame\n",
    "* Je beschrijft kort (mini-verslag hier in de notebook) wat je doet, en wat de inzichten zijn die de visualisatie verschaft.\n",
    "* Je bent in staat om dit mini-verslag ook mondeling te verdedigen, i.e. antwoorden op: wat doe je, waarom doe je dit, en wat was het resultaat.\n",
    "* 1 visualisatie volstaat, meer mag altijd.\n",
    "\n",
    "### Nuttige packages\n",
    "\n",
    "Om jullie al een beetje op weg te helpen, geven we jullie alvast de naam van twee handige en veelvoorkomende visualisatietools die goed werken met pandas DataFrames:\n",
    "\n",
    "1. seaborn\n",
    "2. matplotlib\n",
    "\n",
    "Voor een korte inleiding ivm seaborn kan je hier kijken: https://chrisalbon.com/python/pandas_with_seaborn.html\n",
    "Voor een korte inleiding ivm matplotlib kan je hier kijken: http://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "\n",
    "Natuurlijk moet je vooraleer je aan zo'n visualisatie kan beginnen, al een pandas DataFrame hebben dat de juiste informatie bevat. De eerste stap zal er dus in bestaan om een goede query te schrijven die de nodige informatie uit de gegevensbank weet te halen, gevolgd door een visualisatie van de DataFrame die uit die query volgt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Visualisatie 1: Gewicht vs Salaris **\n",
    "\n",
    "Bij de eerste visualisatie kijken we naar de eventuele correlatie tussen gewicht en salaris van baseball spelers.\n",
    "Dit door een query uit te voeren die het gewicht en het gemiddelde salaris opvraagd voor elke speler in de database.\n",
    "\n",
    "Deze query gaat een stuk sneller met een index op master(playerID), daarom gebruiken we connectie c2 met lahman2016_indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names2 = ['weight', 'avg_salary']\n",
    "\n",
    "def vis_query(connection, column_names):\n",
    "    query=\"\"\"\n",
    "    SELECT m.Weight, AVG(s.Salary)\n",
    "    FROM salaries as s, Master as m\n",
    "    WHERE m.PlayerID = s.PlayerID\n",
    "    GROUP BY(m.PlayerID)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stap 2 & 3\n",
    "    res = run_query(connection, query)         # Query uitvoeren\n",
    "    df = res_to_df(res, column_names)          # Query in DataFrame brengen\n",
    "    \n",
    "    return df\n",
    "\n",
    "vis_pandas = vis_query(c2, column_names2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#Salaris instellen als floating point getal\n",
    "vis_pandas['avg_salary'] = vis_pandas['avg_salary'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vis_np = np.array(vis_pandas)\n",
    "plt.figure()\n",
    "#numpy array verliest kolomnaam, 1ste is weight, 2de is avg_salary\n",
    "plt.title(\"Salaris in functie van gewicht (Spelers)\")\n",
    "plt.xlabel(\"Gewicht [pounds]\")\n",
    "plt.ylabel(\"Salaris\")\n",
    "plt.yscale('log')\n",
    "plot = plt.scatter(vis_np[:, 0], vis_np[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Clusteren **\n",
    "\n",
    "Om de visualisatie nog wat meer pit te geven, onderzoeken we of er groepjes te vinden zijn in de Salaris-gewicht koppels. Dit doen we met clusteren, enerzijds met een voorgezet aantal groepjes of clusters en anderzijds met een automatisch bepaald aantal.\n",
    "\n",
    "KMeans en Ward-Clustering met aantal groepjes (= K) gelijk aan 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster as cl\n",
    "from sklearn import preprocessing as pre\n",
    "\n",
    "#normaliseer data\n",
    "scaler = pre.StandardScaler().fit(vis_np)\n",
    "vis_scl = scaler.transform(vis_np)\n",
    "\n",
    "\n",
    "fig = plt.figure(tight_layout=True)\n",
    "\n",
    "i = 8\n",
    "ax1 = fig.add_subplot(121)\n",
    "clf = cl.AgglomerativeClustering(i)\n",
    "y = clf.fit_predict(vis_scl)\n",
    "ax1.set_title(\"Ward-clustering: K = %d\" % i)\n",
    "ax1.set_xlabel(\"Gewicht [pounds]\")\n",
    "ax1.set_ylabel(\"Salaris\")\n",
    "ax1.set_yscale('log')\n",
    "ax1.scatter(vis_np[:, 0], vis_np[:, 1], c=y, cmap='viridis')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_title(\"KMeans-clustering: K = %d\" % i)\n",
    "ax2.set_xlabel(\"Gewicht [pounds]\")\n",
    "ax2.set_ylabel(\"Salaris\")\n",
    "ax2.set_yscale('log')\n",
    "clf = cl.KMeans(i)\n",
    "y = clf.fit_predict(vis_scl)\n",
    "ax2.scatter(vis_np[:, 0], vis_np[:, 1], c=y, cmap='viridis')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN-clustering op dezelfde data met automatisch bepaald aantal groepjes.\n",
    "Dit is heel parametergevoelig en dus niet gemakkelijker dan met een vooraf bepaalde K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(tight_layout=True)\n",
    "plt.yscale('log')\n",
    "\n",
    "clf = cl.DBSCAN(min_samples = 2, eps = 0.20)\n",
    "\n",
    "#fit op genormaliseerde data\n",
    "y = clf.fit_predict(vis_scl)\n",
    "\n",
    "plt.title(\"DBSCAN-clustering op Salaris - Gewicht data\")\n",
    "p1 = plt.scatter(vis_np[:, 0], vis_np[:, 1], c=y, cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2de visualisatie:\n",
    "#### Weight vs Total homeruns vs AVG Salaris\n",
    "Een tweede visualisatie verderbouwend op de eerste, dit keer in 3D met zowel gewicht, totale aantal homeruns in carrière en gemiddeld salaris van elke speler.\n",
    "\n",
    "Merk op dat in de query tupels met tot_homeruns lager dan 100 weggegooid worden, dit is arbitrair gekozen om zo te proberen duidelijkere visualisaties te vinden. Er zijn namelijk veel spelers met relatief lage aantallen homeruns, waardoor de grafieken hier een te dense puntenwolk weergeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALISATIE 2\n",
    "column_names3 = ['weight', 'tot_homeruns', 'avg_salary']\n",
    "\n",
    "def vis_query(connection, column_names):\n",
    "    query=\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "    SELECT m.weight, SUM(b.HR) as bhr, AVG(s.salary)\n",
    "    FROM salaries as s, Master as m, batting as b\n",
    "    WHERE m.PlayerID = s.PlayerID AND m.playerID = b.playerID\n",
    "    GROUP BY(m.PlayerID)\n",
    "    ORDER BY bhr DESC ) as T\n",
    "    WHERE T.bhr > 100\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stap 2 & 3\n",
    "    res = run_query(connection, query)         # Query uitvoeren\n",
    "    df = res_to_df(res, column_names)          # Query in DataFrame brengen\n",
    "    \n",
    "    return df\n",
    "\n",
    "vis2_pd = vis_query(c2, column_names3)\n",
    "vis2_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcte datatypes gebruiken (floating point getallen ipv Objects)\n",
    "vis2_pd['avg_salary'] = vis2_pd['avg_salary'].astype('float')\n",
    "vis2_pd['tot_homeruns'] = vis2_pd['tot_homeruns'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "vis2_np = np.array(vis2_pd)\n",
    "#numpy array verliest kolomnaam, 1ste is weight, 2de tot_homeruns, 3de avg_salary\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection ='3d')\n",
    "ax.scatter(vis2_np[:, 0], np.log10(vis2_np[:, 1]), np.log10(vis2_np[:, 2]))\n",
    "ax.set_title(\"Plotting Player Weight-Homeruns- AVG Salary\")\n",
    "ax.set_xlabel('Weight')\n",
    "ax.set_ylabel('Total Homeruns (log)')\n",
    "ax.set_zlabel('AVG Salary (log)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Clusteren ** \n",
    "Wederom clusteren we de data, eenmaal met vooraf bepaald aantal clusters, andermaal met automatisch bepaald aantal clusters K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#normaliseer data\n",
    "scaler = pre.StandardScaler().fit(vis2_np)\n",
    "vis2_scl = scaler.transform(vis2_np)\n",
    "\n",
    "i = 5\n",
    "\n",
    "clf = cl.AgglomerativeClustering(i)\n",
    "y = clf.fit_predict(vis2_scl)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection ='3d')\n",
    "ax.scatter(vis2_np[:, 0], np.log10(vis2_np[:, 1]), np.log10(vis2_np[:, 2]), c=y, cmap='viridis')\n",
    "ax.set_xlabel('Weight [pounds]')\n",
    "ax.set_ylabel('Total Homeruns (log)')\n",
    "ax.set_zlabel('AVG Salary (log)')\n",
    "ax.set_title(\"Clustering Players based on Salary, Weight and Homeruns (%d clusters)\" % i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cl.DBSCAN(min_samples = 3, eps = 0.5)\n",
    "y = clf.fit_predict(vis2_scl)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection ='3d')\n",
    "ax.scatter(vis2_np[:, 0], np.log10(vis2_np[:, 1]), np.log10(vis2_np[:, 2]), c=y, cmap='viridis')\n",
    "ax.set_xlabel('Weight')\n",
    "ax.set_ylabel('Total Homeruns (log)')\n",
    "ax.set_zlabel('AVG Salary (log)')\n",
    "ax.set_title('Clustering Player data: automatic number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": true,
   "threshold": "3",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
